<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用Suricata构建网络层入侵检测]]></title>
    <url>%2F2019%2F06%2F22%2F%E4%BD%BF%E7%94%A8Suricata%E6%9E%84%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%B1%82%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[0x00 前言小团队，安全投入有限，入侵检测能力不足，攻防对抗不对等，实在尴尬，迫不得已选择开源方案！ 以下是个人折腾Suricata的一些纪录、想法，不是很成熟、甚至可能观点有错，分享出来，万一有共鸣呢？ 0x01 Suricata简介Suricata是一款基于TCP/IP协议栈解析与安全数据分析引擎： 能够进行实时入侵检测（IDS）、内联入侵预防（IPS）、网络安全监控（NSM）和离线PCAP处理，全面支持Snort规则； Suricata使用强大而广泛的规则和签名语言检查网络流量，并具有强大的Lua脚本支持来检测复杂的威胁； 使用标准的输入和输出格式（如yaml和json），与现有的siem、splunk、logstash/elasticsearch、kibana和其他数据库等工具的集成变得很容易； 入侵检测规则更新活跃，具有较强的社区支持。 支持数据包解码： IPv4, IPv6, TCP, UDP, SCTP, ICMPv4, ICMPv6, GRE Ethernet, PPP, PPPoE, Raw, SLL, VLAN, QINQ, MPLS, ERSPAN HTTP，SSL，TLS，SMB，DCERPC，SMTP，FTP，SSH，DNS，Modbus，ENIP / CIP，DNP3，NFS，NTP，DHCP，TFTP，KRB5，IKEv2 0x02 选择Suricata的原因要做网络层的入侵检、流量分析，能想到的就是Snort、Suricata、Bro，它们是业界比较成熟的开源方案，许多安全公司招聘也列出了熟悉 Suricata 优先,也是很‘优秀’。 Snort始于1998，对于适度流量场景，算是一个比较好的解决方案； Suricata始于2009，我个人理解为是针对大规模网络的snort扩展，在大流量环境下，丢包率源低于snort，性能表现更优秀； Bro是一种被动的开源网络流量分析器，可以检查链路上的所有流量，以查看可疑活动的迹象，大流量环境下表现比较优秀。Bro支持甚至在安全域之外的各种流量分析任务，包括性能测量和帮助解决问题，与Snort或Suricata中的规则集相比，其强大的脚本功能绝对具有更大的优势。 可以参考： https://blog.csdn.net/yrx0619/article/details/81267236 https://bricata.com/resources/white-paper/bro-vs-snot-or-suricata/ 最终，选择Suricata的原因是方便上手，与snort相通，社区资料也比较多，Bro的资料相比之下就少很多了，并且还要花时间研究怎么写脚本，精力与回报不成正比。 0x03 DIY Suricata实际业务环境下： 机房分布也比较多，需要镜像过来做分析的流量分散； 边界流量比较大（单个机房最少的，一分钟也有7、8个g的量），对于这种大流量，直接部署Suricata肯定没啥用，根本扛不住； 分析结果怎么存储展示？ 告警一大堆，谁来看？ 所以： Suricata分布式部署，适配多机房的业务场景，数据统计上报到es； 流量若扛不住，就将导入的镜像流量使用dumpcap进行切割后再给Suricata进行分析； Suricata分析出来的日志存elasticsearch（elk），大数据分析； diy了一个安全分析后台，把已有的hids数据、日志系统的数据关联起来，发现更有价值、紧急层度更高的攻击事件； 综合分析出来的攻击事件，通过硬件FW、系统iptables阻断。 0x04 部署Suricata部署：centos7上部署，部署的版本为：Suricata 4.0.5 1234yum install epel-releaseyum install suricatayum install wget libpcap-devel libnet-devel pcre-devel gcc-c++ automake autoconf libtool make libyaml-devel zlib-devel file-devel jansson-devel nss-devel ELK部署我部署的6.2版本，去网上下载，参照着部署即可，具体过程略 123elasticsearch-6.2.0.rpmlogstash-6.2.0.rpmkibana-6.2.0-x86_64.rpm Suricata规则及配置： 规则入门参考：https://www.secpulse.com/archives/71603.html 默认规则解释参考：https://www.jianshu.com/p/d81db4c352af 1、直接更新替换 1wget https://rules.emergingthreats.net/open/suricata-4.0/emerging.rules.tar.gz 2、suricata规则更新可以使用suricata-update来进行更新 123yum install python-pip python-yamlpip install --pre --upgrade suricata-update 输入suricata-update 会自动进行规则更新，显示当前已经更新与启用了多少规则 1234567891011121314151617181920212223242526[root@test_nsm_nids suricata]# suricata-update6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Using data-directory /var/lib/suricata.6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Using Suricata configuration /etc/suricata/suricata.yaml6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Using /etc/suricata/rules for Suricata provided rules.6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Found Suricata version 4.0.5 at /usr/sbin/suricata.6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Loading /etc/suricata/suricata.yaml6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Disabling rules with proto ntp6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Disabling rules with proto modbus6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Disabling rules with proto enip6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Disabling rules with proto dnp36/5/2019 -- 11:40:35 - &lt;Info&gt; -- Disabling rules with proto nfs6/5/2019 -- 11:40:35 - &lt;Info&gt; -- No sources configured, will use Emerging Threats Open6/5/2019 -- 11:40:35 - &lt;Info&gt; -- Checking https://rules.emergingthreats.net/open/suricata-4.0.5/emerging.rules.tar.gz.md5.6/5/2019 -- 11:40:46 - &lt;Info&gt; -- Fetching https://rules.emergingthreats.net/open/suricata-4.0.5/emerging.rules.tar.gz. 100% - 2352266/2352266 6/5/2019 -- 11:40:50 - &lt;Info&gt; -- Done.6/5/2019 -- 11:40:50 - &lt;Info&gt; -- Ignoring file rules/emerging-deleted.rules6/5/2019 -- 11:40:55 - &lt;Info&gt; -- Loaded 24532 rules.6/5/2019 -- 11:40:56 - &lt;Info&gt; -- Disabled 0 rules.6/5/2019 -- 11:40:56 - &lt;Info&gt; -- Enabled 0 rules.6/5/2019 -- 11:40:56 - &lt;Info&gt; -- Modified 0 rules.6/5/2019 -- 11:40:56 - &lt;Info&gt; -- Dropped 0 rules.6/5/2019 -- 11:40:56 - &lt;Info&gt; -- Enabled 38 rules for flowbit dependencies.6/5/2019 -- 11:40:56 - &lt;Info&gt; -- Backing up current rules.6/5/2019 -- 11:41:02 - &lt;Info&gt; -- Writing rules to /var/lib/suricata/rules/suricata.rules: total: 24532; enabled: 19617; added: 783; removed 8; modified: 13386/5/2019 -- 11:41:03 - &lt;Info&gt; -- Testing with suricata -T. 3、Suricata.yaml配置文件 网络配置： 1234567891011121314151617181920212223242526272829303132333435363738#### Step 1: inform Suricata about your network##vars: # more specifc is better for alert accuracy and performance address-groups: #HOME_NET: &quot;[221.101.0.0/16]&quot; #HOME_NET: &quot;[192.168.0.0/16]&quot; #HOME_NET: &quot;[10.0.0.0/8]&quot; #HOME_NET: &quot;[172.16.0.0/12]&quot; HOME_NET: &quot;any&quot; #EXTERNAL_NET: &quot;!$HOME_NET&quot; EXTERNAL_NET: &quot;any&quot; HTTP_SERVERS: &quot;$HOME_NET&quot; SMTP_SERVERS: &quot;$HOME_NET&quot; SQL_SERVERS: &quot;$HOME_NET&quot; DNS_SERVERS: &quot;$HOME_NET&quot; TELNET_SERVERS: &quot;$HOME_NET&quot; AIM_SERVERS: &quot;$EXTERNAL_NET&quot; DNP3_SERVER: &quot;$HOME_NET&quot; DNP3_CLIENT: &quot;$HOME_NET&quot; MODBUS_CLIENT: &quot;$HOME_NET&quot; MODBUS_SERVER: &quot;$HOME_NET&quot; ENIP_CLIENT: &quot;$HOME_NET&quot; ENIP_SERVER: &quot;$HOME_NET&quot; port-groups: HTTP_PORTS: &quot;80,8081,8080,443&quot; SHELLCODE_PORTS: &quot;!80&quot; ORACLE_PORTS: 1521 SSH_PORTS: &quot;22,37222&quot; DNP3_PORTS: 20000 MODBUS_PORTS: 502 FILE_DATA_PORTS: &quot;[$HTTP_PORTS,110,143]&quot; FTP_PORTS: 21 选择加载的规则：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#### Step 2: select the rules to enable or disable##default-rule-path: /etc/suricata/rulesrule-files:# - botcc.rules - emerging-dos.rules - emerging-exploit.rules - emerging-ftp.rules - emerging-activex.rules - emerging-attack_response.rules - emerging-imap.rules - emerging-info.rules - emerging-malware.rules - emerging-misc.rules - emerging-netbios.rules - emerging-pop3.rules - emerging-rpc.rules - emerging-scan.rules - emerging-shellcode.rules - emerging-smtp.rules - emerging-snmp.rules - emerging-sql.rules - emerging-telnet.rules - emerging-tftp.rules - emerging-user_agents.rules - emerging-web_client.rules - emerging-web_server.rules - emerging-web_specific_apps.rules - emerging-worm.rules - tor.rules# - emerging-icmp_info.rules - emerging-icmp.rules# botcc.portgrouped.rules - ciarmy.rules - compromised.rules# - drop.rules# - dshield.rules# - emerging-chat.rules# - emerging-current_events.rules# - emerging-dns.rules# - emerging-games.rules# - emerging-inappropriate.rules# - emerging-mobile_malware.rules# - emerging-p2p.rules# - emerging-policy.rules# - emerging-scada.rules# - emerging-scada_special.rules - emerging-trojan.rules# - emerging-voip.rules# - decoder-events.rules # available in suricata sources under rules dir# - stream-events.rules # available in suricata sources under rules dir# - http-events.rules # available in suricata sources under rules dir# - smtp-events.rules # available in suricata sources under rules dir# - dns-events.rules # available in suricata sources under rules dir# - tls-events.rules # available in suricata sources under rules dir# - modbus-events.rules # available in suricata sources under rules dir# - app-layer-events.rules # available in suricata sources under rules dir# - dnp3-events.rules # available in suricata sources under rules dir# - ntp-events.rules # available in suricata sources under rules dir 输出检测日志： 1234567891011121314151617181920212223242526272829#### Step 3: select outputs to enable##outputs: - eve-log: enabled: yes filetype: regular #regular|syslog|unix_dgram|unix_stream|redis filename: eve.json types: - alert: metadata: yes tagged-packets: yes xff: enabled: yes mode: extra-data - http: extended: yes - dns: query: yes # enable logging of DNS queries answer: yes # enable logging of DNS answers - tls: extended: yes # enable this for extended logging information - files: force-magic: no # force logging magic on all logged files - smtp: extended: yes # enable this for extended logging information - ssh - flow 参考:https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricatayaml logstash配置suricata_logstash.conf,将suricata入侵检测数据采集到es中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869input &#123;file &#123; path =&gt; [&quot;/var/log/suricata/eve.json*&quot;] codec =&gt; &quot;json&quot; type =&gt; &quot;SuricataIDS&quot;&#125;&#125;filter &#123;if [type] == &quot;SuricataIDS&quot; &#123; date &#123; match =&gt; [ &quot;timestamp&quot;, &quot;ISO8601&quot; ] &#125; ruby &#123; code =&gt; &quot; if event.get(&apos;[event_type]&apos;) == &apos;fileinfo&apos; event.set(&apos;[fileinfo][type]&apos;, event.get(&apos;[fileinfo][magic]&apos;).to_s.split(&apos;,&apos;)[0]) end &quot; &#125; ruby&#123; code =&gt; &quot; if event.get(&apos;[event_type]&apos;) == &apos;alert&apos; sp = event.get(&apos;[alert][signature]&apos;).to_s.split(&apos; group &apos;) if (sp.length == 2) and /\A\d+\z/.match(sp[1]) event.set(&apos;[alert][signature]&apos;, sp[0]) end end &quot; &#125;&#125;if [src_ip] &#123; geoip &#123; source =&gt; &quot;src_ip&quot; target =&gt; &quot;geoip&quot; #database =&gt; &quot;/etc/logstash/conf.d/GeoLiteCity.dat&quot; add_field =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;%&#123;[geoip][longitude]&#125;&quot; ] add_field =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;%&#123;[geoip][latitude]&#125;&quot; ] &#125; mutate &#123; convert =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;float&quot; ] &#125; if ![geoip.ip] &#123; if [dest_ip] &#123; geoip &#123; source =&gt; &quot;dest_ip&quot; target =&gt; &quot;geoip&quot; #database =&gt; &quot;/etc/logstash/conf.d/GeoLiteCity.dat&quot; add_field =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;%&#123;[geoip][longitude]&#125;&quot; ] add_field =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;%&#123;[geoip][latitude]&#125;&quot; ] &#125; mutate &#123; convert =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;float&quot; ] &#125; &#125; &#125;&#125;&#125;output &#123; #stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt;&quot;elastic.*****.com:35608&quot; index =&gt; &quot;suricata_log%&#123;+YYYY.MM&#125;&quot; &#125;&#125; 0x05 数据分析1）suricata数据创建Kibana看板，进行数据分析最为简易，可以下载Kibana看板所需的json文件，并添加到Kibana中： 123https://aka.ms/networkwatchersuricatadashboardhttps://aka.ms/networkwatchersuricatavisualizationhttps://aka.ms/networkwatchersuricatasavedsearch 启动suricata进行网络入侵检测后，生成eve.json文件，使用ELK组件处理该文件，并在Kibana上展示告警，具体界面如下： 2）综合联动分析这里的综合联动分析，就是吧目前有点数据关联起来，比如hids、waf（基于elk）、cmdb等 例如： 情景1、suricata检测到有大量扫描爆破行为，我把该事件的源IP跟cmdb数据进行关联，如果匹配上了，那么很有可能是内部机器沦陷发起了进一步的扫描攻击，事件紧急程度高，得赶紧响应！ 情景2、suricata检测到大量针对系统层面的攻击行为，关连hids日志，若有一定的匹配，那么攻击成功的可能性比较高，需要引起安全的高度关注。 …… 我这里提到的关联分析也是比较简单粗暴，主要目的是为了减少单一告警的误报率，关联分析过后，准确率会有一定提升（没数据支撑，说个卵） 经过分析之后，可以将攻击ip推送给硬件防火墙进行封禁，没过墙的业务推给服务器iptables封禁。 0x06 面临的困境（坑点） Suricata规则基本依托于社区能力，没有人力来进行规则维护 机房出口流量较大，多地多机房，流量镜像过来，Suricata检测引擎的性能会成为瓶颈(服务器成本不小) 镜像过来的流量，可能有掉包，目前还咩想到啥好的方案 告警一大堆，根本没人看（得过来） 这玩意儿，搞着搞着可能就成了半成品 总之，有总比没有好，至少敢根老板说，我们安全是有感知的了，呵呵]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用OSSEC构建主机层入侵检测]]></title>
    <url>%2F2018%2F03%2F22%2F%E4%BD%BF%E7%94%A8OSSEC%E6%9E%84%E5%BB%BA%E4%B8%BB%E6%9C%BA%E5%B1%82%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[0xFFFF FFFFreload一篇文档，并更新了部分内容。 0x00 前言FW、WAF、NIDS、HIDS都是企业构建自己的安全防御体系的基础，整合的好就成了ATA(Advanced Threat Analytics高级威胁分析)。 这篇文章记录了前段时间在公司搞基础安全建过程中，基于ossec搞hids的一些记录和总结，供大家参考。 @ayazero有篇文章里面有一段大概是这样说的：你特么就只会玩玩ossec？对不起，这只是个数千规模量级的解决方案，无论是架构，还是检测深度乃至场景覆盖率都无法解决更大规模下的问题。 所以，这里的主要适用范围是在中小型互联网企业，尤其是安全人员较少，然后又不怎么重视安全（不愿意花钱）的那种，土豪公司可以直接忽略。 0x01 OSSEC相关介绍OSSEC是一款开源的基于主机的入侵检测系统。它具备日志分析，文件完整性检查，策略监控，rootkit检测，实时报警以及联动响应等功能。它支持多种操作系统：Linux、Windows、MacOS、Solaris、HP-UX、AIX。 0x02 选择OSSEC的原因主机安全监控之前已经开始在做，大佬走了我来接盘。要搞hids，首先想到的是ossec，同时也去调研了一下相关的开源产品。 开源产品 简介 项目地址 ossec 在众多互联网企业中广泛运用 https://www.ossec.net/ wazuh 基于ossec扩展出来的，结合了Elastic Stack https://wazuh.com/ osquery facebook开源的osquery，通过集成osquery来实现快速监控系统安全 https://osquery.io/ yulong-hids 同程安全团队开源的HIDS https://github.com/ysrc/yulong-hids AgentSmith HIDS 点融安全团队开源的HIDS https://github.com/DianrongSecurity/AgentSmith-HIDS 考虑到ossec稳定性稳定性稳定性、案例资料也较多、容易上手，而且前期已经在边缘业务部署测试，所以继续选择ossec。yulong、AgentSmith也相当不错，但刚准备搞hids的时候它还没开源出来呐。 在正式动工之前，就想着有很多坑需要填，这里列举了一些，这是一个小白的绝望： [x] 大规模的机器，如何初始化部署ossec的？ [x] 大规模的agent如何管理？如何管理、下发规则？ [x] 集群化的部署，如何统一管理？ [x] 海量日志怎样存储，怎样做数据分析？上来这么多报警，如何提取有效信息？如何闭环？ [x] 如何做一些关键的安全监控策略：基线扫描、webshell扫描、反弹shell监控等？ [x] 文件系统复杂、业务量大，性能瓶颈该如何解决？ 0x03 HIDS架构构思对于企业来说，主机数量多，机房遍布各地，业务环境不同，日志量较大较分散，如果只是简单的部署ossec估计也没多大意义。所以在初期就在思考借助这个检测框架，我们可以实现那些功能和检测能力。 HIDS核心功能： HIDS数据处理流程： ossec-agent ：用于收集服务器信息、计划任务、监听端口、服务、系统日志、用户列表，实时监控文件操作行为、网络连接，系统安全配置核查（基线扫描）、webshell扫描、反弹shell监控等，初步筛选整理后传输到Server节点。 ossec-server：集群化部署，用于解析用户定义的规则，对从各Agent接收到的信息和行为进行分析检测和保存，对文件变化、异常登录、异常网络连接行为等进行分析并告警，从而实现对入侵行为实时预警。 Elasticsearch：日至存储、聚合、分析 Mysql：存储配置信息、cmdb资产信息、告警信息、监控组信息 Redis：任务队列、告警队列、消息推送队列 Web后台，搜集展示来至es的日志，提供给安全人员或运维人员；包括监控日志、告警消息查询，数据统计、监控组管理、主机管理、告警过滤、规则查看、配置下发等功能。 0x04 实践并优化我们把HIDS数据流抽象为采集层、入侵检测层、存储层、分析决策层，架构解析如下： 同时也列出了我们需要解决的核心问题： Agent部署步骤繁琐，大规模部署存在难点 Agent管理问题 默认入侵检测能力有限 告警多，入侵事件误判多 事件处置流程欠佳 1.部署优化，提升覆盖率 优化前： 默认只支持源码安装、安装步骤繁琐、编译安装还容易出错 agent与server端签名认证匹配过程繁琐 需要人工介入部署，工作量特别大 优化后： 我把源码包定制化修改之后，打成rpm包，yum源方式部署；支持centos6.，centos7.系列 定制化编写部署脚本及部署流程，减轻了部署工作带来的压力 多区域的主机，server多区域分布式部署，最终数据汇总到一处即可 需要注意：每一台ossec-server默认支持256个agent，最大支持2048个agent。要想支持2048个agent，需要在安装之前设置一下。 1234567[root@ossec-server ~]# cd ossec-hids/src/[root@ossec-server src]# make setmaxagentsSpecify maximum number of agents: 2048Maximum number of agents set to 2048.[root@ossec-server src]# cd ..[root@ossec-server ossec-hids]# ./install.sh... 2.8版本的ossec，比较麻烦的是批量添加agent，因为其通信认证特别麻烦。需要想办法批量生产agent的key文件，然后交换给agent。当时我们借助了已有的ops平台，写了一些脚本，自动化的完成了以上的认证过程。 可以参考drops:OSSEC服务端配置客户端批量部署方案，然后根据自己情况调整。 较新版本（比如v3.2.0）完美解决了以上问题： 123451、IPv6支持，满足未来业务IPv6需求2、ossec-authd认证机制更加完善，安全系数提高，解决当前部署流程复杂易出错的问题3、Configuration options更加完善，可以配置更灵活的监控项4、更新检测规则/解码器5、修复若干bug 添加agent可能有两种情况： 已经线上运行的服务器（手动部署或批量部署） 运维人员到运维平台，选择指定机器执行部署模版命令即可完成部署,部署成功率&gt;90% 新上线的服务器 自动装机，执行系统初始化脚本时，针对平台业务路径的主机，自动部署安全监控agent,部署成功率&gt;95% 2.主机及规则管理优化 优化前： Agent仅有ip信息，这ip是属于什么业务、谁负责，告警出来应该找谁去处理 怎样去查看agent状态？只能通过上server机器通过命令去查看 怎样去管理他的入侵检测规则？不知道目前有哪些规在跑？ 优化后： 针对这样的问题，我们拉取了cmdb数据，同步CMDB关联业务信息，将这些分散的信息关联起来，成为一个完成的信息链条 联动CMDB，安全agent监控覆盖到所有业务，滴水不漏 在ossec server机器编写了相应的查询接口，自动化的去同步各个server下的agent信息 编写一整套接口并结合active-response机制去更新agent端的规则（后期换成了其它方式，被动更新规则） 效果： 监控组管理 主机管理 规则管理 3.丰富检测能力，提升安全事件感知效率 ossec默认拥有日志分析，文件完整性检查，rootkit检测，这些默认的规则，覆盖得比较多、比较泛，没有针对性；比如，我监控敏感文件变化，它检测出来的告警只会告诉你文件发生了变化，文件路径是什么什么； 对此我针对性的优化、把一些关键的文件、配置监控单独做成一条规则， 比如说监控到定时任务变化了，单独告警说定时任务变化了、监控到iptables改变单独提示告警、监控到iptables关闭了，就会产生对应的告警。 不同告警可以设置不同的level，以区别重要程度。 另一方面，改写了agent，加入一些自定义的检测脚本，用ossec检测框架去定时脚本执行，反馈结果到我的server端并进行分析。 系统安全配置核查，比如说ssh配置，是否修改了默认的22端口，是否启用了ssh key认证，是否禁用了密码登录、redis是否未设置密码、php.ini文件是否配置合理等。 另外一项就是针对webshell的监控 反弹shell检查等 如下，是ossec目录结构： 123456789101112131415161718192021222324252627282930313233343536/ossec/├── active-response #主动响应脚本├── agentless├── bin #二进制文件，主程序logcollector、syscheck等│ ├── agent-auth│ ├── manage_agents│ ├── ossec-agentd #agent守护进程│ ├── ossec-control #agent操作入口│ ├── ossec-execd #agent主动响应进程，用于执行server端预定的操作│ ├── ossec-logcollector #agent日志搜集进程│ ├── ossec-lua│ ├── ossec-luac│ ├── ossec-syscheckd #agent文件监控进程│ └── util.sh├── etc #配置文件│ ├── client.keys #通信密钥│ ├── ossec.conf │ ├── ossec-init.conf│ ├── ossec_monitor ＃配合ops的性能监控│ └── shared ├── logs #日志文件│ ├── active-responses.log│ └── ossec.log├── queue ＃监控任务队列│ ├── alerts│ ├── diff│ ├── ossec│ ├── rids│ └── syscheck├── shell #自定义的安全检测脚本│ ├── systemCheck.sh #系统基线扫描│ ├── webshellScan.py #websehll扫描│ ├── ReverseshellScan.py #反弹shell监控│ ├──......├── tmp└── var 例如，自定义安全检查脚本‘systemCheck.sh’,用于检查系统安全基线配置情况: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152check_ssh()&#123; ssh_config_path=&apos;/etc/ssh/sshd_config&apos; result=`cat $ssh_config_path | grep &apos;^PasswordAuthentication *yes&apos;` if [ -n &quot;$result&quot; ];then echo &apos;Notice: ssh can login with password&apos; fi result=`cat $ssh_config_path | grep &apos;^Port *2222$&apos;` if [ ! -n &quot;$result&quot; ];then echo &apos;Notice: ssh listen port not 2222&apos; fi result=`cat $ssh_config_path | grep &apos;^PermitEmptyPasswords *yes&apos;` if [ -n &quot;$result&quot; ];then echo &apos;Notice: ssh allow login with empty password&apos; fi&#125;check_system()&#123; result=`awk -F: &apos;($3 == &quot;0&quot;) &#123; print $1 &#125;&apos; /etc/passwd | grep &apos;[^root]&apos; ` if [ -n &quot;$result&quot; ];then echo &apos;Notice:Other root account:&apos;$result fi result=`awk -F: &apos;($2 == &quot;&quot;) &#123; print $1 &#125;&apos; /etc/shadow | grep [a-zA-Z]` if [ -n &quot;$result&quot; ];then echo &apos;Notice: account has empty passwd&apos;$result fi&#125;check_sshcheck_system ossec 配置文件中添加如下内容，每隔10小时进行一次扫描： 12345678910&lt;localfile&gt; &lt;log_format&gt;command&lt;/log_format&gt; &lt;command&gt;/bin/bash /var/ossec/shell/systemCheck.sh&lt;/command&gt; &lt;frequency&gt;36000&lt;/frequency&gt;&lt;/localfile&gt;&lt;localfile&gt; &lt;log_format&gt;command&lt;/log_format&gt; &lt;command&gt;python /var/ossec/shell/webshellScan.py&lt;/command&gt; &lt;frequency&gt;36000&lt;/frequency&gt;&lt;/localfile&gt; 类似的，监控系统iptables变化、authorized_keys变化。 1234567891011&lt;localfile&gt; &lt;log_format&gt;command&lt;/log_format&gt; &lt;command&gt;iptables -L -n|md5sum|awk &apos;&#123;print $1&#125;&apos;&lt;/command&gt;&lt;/localfile&gt;&lt;localfile&gt; &lt;localfile&gt; &lt;log_format&gt;command&lt;/log_format&gt; &lt;command&gt;cat /root/.ssh/authorized_keys|md5sum|awk &apos;&#123;print $1&#125;&apos;&lt;/command&gt;&lt;/localfile&gt; 这里特别说下针对webshell扫描的优化： webshell的监控，这里我只是做了简单的文件静态特征检测，手段还有很多需要拔高的地方。 123456789101.扫描性能优化2.webshell规则库优化@过程中参考了以下文章，具有一定的借鉴意义：https://mp.weixin.qq.com/s/oZ7Jmo_rIblGYArHecn7lQhttps://mp.weixin.qq.com/s/3Zx2FTXXxpTiqe56b8hJQghttps://mp.weixin.qq.com/s/8PauKA6KU3TXp2FEmcoqeQhttps://mp.weixin.qq.com/s/yh_uX8jPfbn-_wzGOkugaA 性能优化 最初，扫描性能这块没有经过严谨的测试，只是做了一些粗略的控制。当webshell检测脚本部署到一些web目录深度较大、文件数量较多、业务比较多的机器上的时候，性能出现了瓶颈，磁盘io一度飙高到90%以上且持续时间较长，没法完了，赶紧下线了webshell扫描的功能。影响到业务，锅非常大！ webshell检测主要靠遍历目录／文件的方式，正则批评特征函数进行检测，当时优化的思路是引入cgroup来控制，同时在代码中引入一些特征变量来做控制： 12345671.最大目录深度；（避免目录过深导致的内存消耗）max_directory_depth 2.最大扫描文件大小；（避免大文件都会消耗过多的资源）max_file_size 3.目录遍历时间间隔；（避免大文件都会消耗过多的IO资源）walkdir_time_span 4.文件检查间隔；（避免CPU利用率会爬升到100%）regex_time_span 设置不同regex_time_span值，生成不同时间间隔下的系统资源损耗的实验结果,取200s中的平均值（实验数据）： 实验后关键参数取值如下： 1234max_directory_depth = 10max_file_size = 100000walkdir_time_span = 0.005regex_time_span = 0.05 优化前后webshell扫描性能（IO）对比： webshell规则优化 webshell监控效果展示： 添加互联网收集的一些webshell规则特征（php、java）： 收集了175个webshell文件和500个正常文件进行实验： 1234查杀率（优化前）：111/175 63%查杀率（优化后）：147/175 84%误检率（优化前）：0/500 0％误检率（优化后）：2/500 0.4% 对比 查杀率 误检率 优化前 63% 0.0% 优化后 84% 0.4% 牺牲了误报率，提升了查杀率，可以接受的。 4.快速分析&amp;流程闭环，提升事件处置效率数据分析与展示： 前面解决了部署问题、一定程度上优化了入侵检测规则，获取到的检测数据如何进行分析，得到的入侵事件如何有效的反馈处置，只是一个值得思考的问题。 ossec自己也推出了一个免费的webui界面，对告警内容做展示，但是没有做任何的统计分析，不能满足我们对时机需求，我从两方面最改良了这个问题： 自写hids web管理后台，入侵事件告警记录、处置情况记录、agent管理、监控组管理、规则管理等； 结合elk做数据分析，快速的解决数据查询、统计的问题； 结合其它安全基础设施日志进行关联分析。 告警闭环：ossec跑了一段时间，筛选出了一份常规的监控告警项加入邮件告警，其它的事件只纪录不告警。 12345678910风险级别定义：高：疑似入侵事件或不符合安全配置的检测项，高度关注；中：非正常业务运维操作，可疑；低：某些正常的操作，可提供给后续安全事件调查溯源。将监控事件划分为（1-12）Level；Level越高，事件风险程度越高，Level&gt;=7时，触发邮件告警。1-6 Level：一般事件（低）7-9 Level：可疑事件（中）10－12 Level：高度关注事件（高）注：目前采用单一事件告警，后期将关联多个事件计算风险权重后进行组合告警，将降低误报率。 我们直接把一些风险值较高、且较容易判断的监控告警项同步推送給业务机器负责人，让他们第一事件了解安全状况。接收到告警信息后，运维人员可进行告警反馈（数据同步到安全中心），安全人员可根据反馈情况，进行应急处置及数据分析： 若告警事件为正常操作，可点击“忽略告警”按钮， 若该事件确实存在可疑，可点击“确认异常”按钮，事件升级。 iptables变化或关闭 crontab变化 关键配置文件发生变化 网卡模式发生变化 SSH登陆失败 SSH爆破 …… 通常，这几类告警，运维人员更加清楚是否异常，方便确认是否为安全问题，同时还可以协助做一些异常排查。 0x05 收益 todo 数据积累，稳定运行 组合告警，提升告警准确率 入侵检测功能持续优化]]></content>
  </entry>
  <entry>
    <title><![CDATA[几个高精度IP定位网站]]></title>
    <url>%2F2017%2F09%2F30%2F%E5%87%A0%E4%B8%AA%E9%AB%98%E7%B2%BE%E5%BA%A6IP%E5%AE%9A%E4%BD%8D%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[几个高精度IP定位网站：https://ip.rtbasia.com/https://www.opengps.cn/Data/IP/LocHighAcc.aspxhttp://www.ipplus360.com/http://chaipip.com/ IP信息综合查询：https://www.ipip.net/ip.htmlhttps://bgp.he.net/]]></content>
  </entry>
  <entry>
    <title><![CDATA[结合Fluentd实现ngx_lua_waf页面展示]]></title>
    <url>%2F2016%2F10%2F20%2F%E7%BB%93%E5%90%88Fluentd%E5%AE%9E%E7%8E%B0ngx_lua_waf%E9%A1%B5%E9%9D%A2%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[0x00 概述最近在看lua_waf,看看怎么搞个web界面出来，于是有了这篇笔记。 上图是大佬分享的waf日志处理流程，不过我这篇文章讲的就简单多了，如下, 纯属搞着玩儿： ngx_lua_waf简介 ngx_lua_waf，是一个轻量级、高性能的WAF模块。 防止sql注入，本地包含，部分溢出，fuzzing测试，XSS, SSRF等web攻击 防止svn/备份之类文件泄漏 防止ApacheBench之类压力测试工具的攻击 屏蔽常见的扫描黑客工具，扫描器 屏蔽异常的网络请求 屏蔽图片附件类目录php执行权限 防止webshell上传 详情（安装方法）见：https://github.com/loveshell/ngx_lua_waf Fluentd简介 Fluentd，是一个开源收集事件和日志系统，它目前提供150+扩展插件让你存储大数据用于日志搜索，数据分析和存储。这里我们用fluentd搜集lua_waf日志。 官网：http://www.fluentd.org/ 文档中心：http://docs.fluentd.org/v0.12/articles/quickstart 0x01 Fluentd安装lua_waf安装略，网上有很多教程，直接开始fluentd部署。 1.通过rpm安装，执行如下命令（如果有报错，按实际报错提示处理即可）：1$ curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh 2.安装好之后便可以启动： 1234$ /etc/init.d/td-agent start Starting td-agent: [ OK ]$ /etc/init.d/td-agent statustd-agent (pid 21678) is running... 3.配置，如何取日志，如何进行处理分析都在这里进行配置（td-agent.conf）： 1$ sudo vi /etc/td-agent/td-agent.conf 4.必要的插件，我们这里是要将取得的日志送到mysql做分析以及页面展示，所以需要下载fluent-plugin-mysql（fluentd默认没有mysql插件）。 1gem地址：https://rubygems.org/gems/fluent-plugin-mysql/versions/0.1.5 安装命令： 1234yum install mysql-devel（依赖包）/usr/sbin/td-agent-gem install jsonpath/usr/sbin/td-agent-gem install mysql2-cs-bind/usr/sbin/td-agent-gem install fluent-plugin-mysql -v 0.1.5 ngx_lua_waf日志格式 init.lua代码片段: 1234567891011121314151617#ngx_lua_waf拦截日志格式，能够与fluentd正则匹配。function log(method,url,data,ruletag) if attacklog then local realIp = getClientIp() local ua = ngx.var.http_user_agent local servername=ngx.var.server_name local time=ngx.localtime() if ua then line = realIp..&quot; &quot;..servername..&quot; \&quot;&quot;..time..&quot;\&quot; \&quot;&quot;..method..&quot; &quot;..servername..url..&quot;\&quot; \&quot;&quot;..data..&quot;\&quot; \&quot;&quot;..ua..&quot;\&quot; \&quot;&quot;..ruletag..&quot;\&quot;\n&quot; else line = realIp..&quot; &quot;..servername..&quot; \&quot;&quot;..time..&quot;\&quot; \&quot;&quot;..method..&quot; &quot;..servername..url..&quot;\&quot; \&quot;&quot;..data..&quot;\&quot; - \&quot;&quot;..ruletag..&quot;\&quot;\n&quot; end local filename = logpath..&apos;/&apos;..servername..&quot;_sec.log&quot; write(filename,line) endend fluentd配置 td-agent.conf片段： 12345678910111213141516171819202122#将/usr/local/nginx/logs/hack/ngx_lua_waf_sec.log日志实时同步到mysql&lt;source&gt; @type tail path /usr/local/nginx/logs/hack/ngx_lua_waf_sec.log pos_file /var/log/td-agent/httpd-access.log.pos format /^(?&lt;ip&gt;[^ ]*) (?&lt;website&gt;[^ ]*) &quot;(?&lt;time&gt;[^\&quot;]*)&quot; &quot;(?&lt;method&gt;\S+)(?: +(?&lt;path&gt;[^\&quot;]*))?&quot; &quot;(?&lt;demo&gt;[^\&quot;]*)&quot; &quot;(?&lt;agent&gt;[^\&quot;]*)&quot; &quot;(?&lt;rule&gt;[^\&quot;]*)&quot;$/ time_format %Y-%m-%d %H:%M:%S tag test.http&lt;/source&gt;&lt;match test.**&gt; @type mysql_bulk host 172.20.3.64 database waf username root password qwe@123456 column_names id,ip,website,time,method,path,demo,agent,rule table waflog time_format %Y-%m-%d %H:%M:%S flush_interval 3s&lt;/match&gt; 0x02 mysql接收waf日志下面这张表存放waf的拦截日志，比较简单。接收上面td-agent传过来的数据。 123456789101112131415161718192021222324252627282930313233use pscan;SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for waflog-- ----------------------------DROP TABLE IF EXISTS `waflog`;CREATE TABLE `waflog` ( `id` int(100) NOT NULL, `ip` varchar(100) DEFAULT NULL, `website` varchar(255) DEFAULT NULL, `time` datetime DEFAULT NULL, `method` varchar(255) DEFAULT NULL, `path` varchar(255) DEFAULT NULL, `demo` varchar(255) DEFAULT NULL, `agent` varchar(255) DEFAULT NULL, `rule` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=MyISAM DEFAULT CHARSET=utf8;-- ------------------------------ Records of waflog-- ----------------------------INSERT INTO `waflog` VALUES (&apos;1&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;2&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;3&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;4&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;5&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;6&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;7&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;8&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;);INSERT INTO `waflog` VALUES (&apos;9&apos;, &apos;172.20.3.64&apos;, &apos;www.maliciouskr.cc&apos;, &apos;2016-09-08 20:18:03&apos;, &apos;GET&apos;, &apos;/dump.php?&lt;img&lt;!--+--&gt; src=x onerror=alert(9549);//&gt;&lt;!-- --&gt;&apos;, &apos;-&apos;, &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.21 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.21&apos;, &apos;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(\\\&quot;&apos;); 0x03 页面展示 源码（php+mysql+Bootstrap）见github，代码质量为初学者水平，见谅。]]></content>
      <tags>
        <tag>Testing</tag>
        <tag>入侵检测</tag>
        <tag>waf</tag>
      </tags>
  </entry>
</search>
